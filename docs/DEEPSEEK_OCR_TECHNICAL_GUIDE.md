# DeepSeek-OCR æŠ€è¡“æ–‡ä»¶ï¼šæ·±å…¥æ·ºå‡ºæŒ‡å—

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¥æœŸ**: 2025-11-10  
**ä½œè€…**: DeepSeek-OCR API Team

---

## ç›®éŒ„

1. [DeepSeek-OCR ä»‹ç´¹](#1-deepseek-ocr-ä»‹ç´¹)
2. [Unsloth èˆ‡ DeepSeek-OCR](#2-unsloth-èˆ‡-deepseek-ocr)
3. [ç³»çµ±å®‰è£èˆ‡ç’°å¢ƒè¨­å®š](#3-ç³»çµ±å®‰è£èˆ‡ç’°å¢ƒè¨­å®š)
4. [API ä½¿ç”¨æŒ‡å—èˆ‡æ‡‰ç”¨é ˜åŸŸ](#4-api-ä½¿ç”¨æŒ‡å—èˆ‡æ‡‰ç”¨é ˜åŸŸ)
5. [é€²éšä¸»é¡Œ](#5-é€²éšä¸»é¡Œ)
6. [å¸¸è¦‹å•é¡Œ](#6-å¸¸è¦‹å•é¡Œ)

---

## 1. DeepSeek-OCR ä»‹ç´¹

### 1.1 é–‹ç™¼èƒŒæ™¯

**DeepSeek-OCR** æ˜¯ç”± **DeepSeek AI** é–‹ç™¼çš„å°ˆæ¥­ç´šå…‰å­¸å­—ç¬¦è­˜åˆ¥ï¼ˆOCRï¼‰æ¨¡å‹ï¼Œæ–¼ 2025 å¹´ç™¼å¸ƒã€‚DeepSeek AI æ˜¯ä¸€å®¶å°ˆæ³¨æ–¼å¤§å‹èªè¨€æ¨¡å‹å’Œè¦–è¦ºèªè¨€æ¨¡å‹ç ”ç©¶çš„äººå·¥æ™ºæ…§å…¬å¸ï¼Œå…¶é–‹ç™¼çš„ DeepSeek ç³»åˆ—æ¨¡å‹åœ¨å¤šå€‹é ˜åŸŸéƒ½å±•ç¾å‡ºå“è¶Šæ€§èƒ½ã€‚

### 1.2 æ ¸å¿ƒç‰¹é»

#### ğŸ¯ æŠ€è¡“è¦æ ¼

- **æ¨¡å‹å¤§å°**: 3B åƒæ•¸ï¼ˆ30å„„åƒæ•¸ï¼‰
- **æ¨¡å‹æ¶æ§‹**: Vision-Language Model (VLM)
- **åŸºç¤æ¶æ§‹**: DeepSeek V2 æ¶æ§‹
- **è¦–è¦ºç·¨ç¢¼å™¨**: è‡ªå®šç¾©çš„è¦–è¦º Transformer
- **èªè¨€æ¨¡å‹**: DeepSeek-V2 èªè¨€éª¨å¹¹ç¶²è·¯
- **è¨“ç·´æ•¸æ“š**: å¤§è¦æ¨¡å¤šèªè¨€æ–‡æª”æ•¸æ“šé›†

#### âš¡ æ€§èƒ½å„ªå‹¢

1. **é«˜ç²¾ç¢ºåº¦**: é”åˆ° 97% çš„å­—ç¬¦è­˜åˆ¥ç²¾ç¢ºåº¦
2. **é«˜æ•ˆç‡**: è¦–è¦º token ä½¿ç”¨é‡åƒ…ç‚ºæ–‡å­— token çš„ 1/10
3. **æ•ˆèƒ½æå‡**: æ¯”ç´”æ–‡å­— LLM å¿« 10 å€
4. **ä½è³‡æº**: 3B åƒæ•¸æ¨¡å‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ™‚é™ä½è¨ˆç®—éœ€æ±‚

#### ğŸŒŸ é—œéµå‰µæ–°

##### Context Optical Compressionï¼ˆä¸Šä¸‹æ–‡å…‰å­¸å£“ç¸®ï¼‰

DeepSeek-OCR çš„æ ¸å¿ƒå‰µæ–°æ˜¯ **Context Optical Compression** æŠ€è¡“ï¼š

```
å‚³çµ± OCR æµç¨‹:
åœ–åƒ â†’ ç‰¹å¾µæå– â†’ å­—ç¬¦è­˜åˆ¥ â†’ æ–‡å­—è¼¸å‡º

DeepSeek-OCR æµç¨‹:
åœ–åƒ â†’ 2D ä½ˆå±€ä¿æŒ â†’ è¦–è¦º Token å£“ç¸® â†’ ä¸Šä¸‹æ–‡ç†è§£ â†’ æ–‡å­—è¼¸å‡º
```

**å·¥ä½œåŸç†**:
1. å°‡ 2D åœ–åƒä½ˆå±€è½‰æ›ç‚ºè¦–è¦º tokens
2. ä¿æŒæ–‡æª”çš„ç©ºé–“é—œä¿‚å’Œçµæ§‹ä¿¡æ¯
3. é€šéå£“ç¸®ç®—æ³•æ¸›å°‘ token æ•¸é‡
4. çµåˆèªè¨€æ¨¡å‹é€²è¡Œä¸Šä¸‹æ–‡ç†è§£

é€™ç¨®æ–¹æ³•ä½¿å¾—æ¨¡å‹èƒ½å¤ ï¼š
- ç†è§£è¡¨æ ¼çµæ§‹
- ä¿æŒæ®µè½æ ¼å¼
- è­˜åˆ¥æ‰‹å¯«æ–‡å­—
- è™•ç†å¤šæ¬„ä½ä½ˆå±€

### 1.3 åŠŸèƒ½ç‰¹æ€§

#### ğŸ“„ æ”¯æ´çš„æ–‡æª”é¡å‹

1. **å°åˆ·æ–‡æª”**
   - æ›¸ç±ã€é›œèªŒ
   - å ±ç´™ã€è«–æ–‡
   - å•†æ¥­æ–‡ä»¶

2. **æ‰‹å¯«æ–‡æª”**
   - æ‰‹å¯«ç­†è¨˜
   - ç°½å
   - æ‰‹ç¹ªåœ–è¡¨

3. **çµæ§‹åŒ–æ–‡æª”**
   - è¡¨æ ¼æ•¸æ“š
   - ç™¼ç¥¨ã€æ”¶æ“š
   - è¡¨å–®

4. **è¤‡é›œä½ˆå±€**
   - å¤šæ¬„ä½æ–‡æª”
   - æ··åˆåœ–æ–‡
   - æŠ€è¡“åœ–è¡¨

#### ğŸŒ èªè¨€æ”¯æ´

- **ä¸­æ–‡**: ç°¡é«”ä¸­æ–‡ã€ç¹é«”ä¸­æ–‡
- **è‹±æ–‡**: ç¾å¼è‹±èªã€è‹±å¼è‹±èª
- **æ—¥æ–‡**: å¹³å‡åã€ç‰‡å‡åã€æ¼¢å­—
- **éŸ“æ–‡**: è«ºæ–‡
- **å…¶ä»–**: æ³•æ–‡ã€å¾·æ–‡ã€è¥¿ç­ç‰™æ–‡ç­‰

### 1.4 ä½¿ç”¨æŠ€è¡“

#### æ¨¡å‹æ¶æ§‹å±¤

```
DeepSeek-OCR æ¶æ§‹:

è¼¸å…¥åœ–åƒ (HÃ—WÃ—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vision Encoder     â”‚  â† è¦–è¦ºç·¨ç¢¼å™¨
â”‚  - ViT-based        â”‚  
â”‚  - Patch Embedding  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è¦–è¦º Tokens (NÃ—D)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optical Compression â”‚  â† å…‰å­¸å£“ç¸®å±¤
â”‚  - Context Aware    â”‚
â”‚  - 10Ã— Reduction    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
å£“ç¸® Tokens (N/10Ã—D)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Language Backbone   â”‚  â† èªè¨€æ¨¡å‹
â”‚  - DeepSeek-V2      â”‚
â”‚  - Causal LM        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æ–‡å­—è¼¸å‡º
```

#### æ·±åº¦å­¸ç¿’æ¡†æ¶

- **PyTorch**: 2.0+
- **Transformers**: 4.57.1
- **CUDA**: 11.8+ / 12.x
- **Flash Attention**: æ”¯æ´åŠ é€Ÿæ¨ç†
- **BFloat16**: æ··åˆç²¾åº¦è¨“ç·´

#### æœ€ä½³åŒ–æŠ€è¡“

1. **æ¨¡å‹é‡åŒ–**
   - æ”¯æ´ 4-bit é‡åŒ– (é™ä½ 75% è¨˜æ†¶é«”)
   - æ”¯æ´ 8-bit é‡åŒ– (é™ä½ 50% è¨˜æ†¶é«”)
   - LoRA å¾®èª¿

2. **æ¨ç†åŠ é€Ÿ**
   - Xformers å„ªåŒ–
   - Flash Attention 2
   - KV Cache å„ªåŒ–

3. **è¨˜æ†¶é«”å„ªåŒ–**
   - Gradient Checkpointing
   - CPU Offloading
   - æ¨¡å‹ä¸¦è¡Œ

### 1.5 é–‹ç™¼ç›®çš„èˆ‡é¡˜æ™¯

#### ä¸»è¦ç›®æ¨™

1. **æ–‡æª”æ•¸å­—åŒ–**: åŠ é€Ÿç´™è³ªæ–‡æª”è½‰æ›ç‚ºæ•¸å­—æ ¼å¼
2. **ç„¡éšœç¤™è¨ªå•**: å”åŠ©è¦–è¦ºéšœç¤™äººå£«é–±è®€æ–‡æª”
3. **è·¨èªè¨€ç†è§£**: å¯¦ç¾å¤šèªè¨€æ–‡æª”çš„è‡ªå‹•ç¿»è­¯èˆ‡ç†è§£
4. **çŸ¥è­˜æå–**: å¾å¤§é‡æ–‡æª”ä¸­å¿«é€Ÿæå–é—œéµè³‡è¨Š

#### æ‡‰ç”¨é¡˜æ™¯

DeepSeek-OCR æ—¨åœ¨æˆç‚ºï¼š
- ä¼æ¥­æ–‡æª”ç®¡ç†çš„åŸºç¤è¨­æ–½
- æ•™è‚²é ˜åŸŸçš„è¼”åŠ©å·¥å…·
- æ­·å²æ–‡ç»æ•¸å­—åŒ–çš„åˆ©å™¨
- AI æ‡‰ç”¨çš„è¦–è¦ºç†è§£å¼•æ“

---

## 2. Unsloth èˆ‡ DeepSeek-OCR

### 2.1 Unsloth ç°¡ä»‹

**Unsloth** æ˜¯ç”± Unsloth AI é–‹ç™¼çš„æ·±åº¦å­¸ç¿’å„ªåŒ–æ¡†æ¶ï¼Œå°ˆé–€ç”¨æ–¼åŠ é€Ÿå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè¦–è¦ºèªè¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è¨“ç·´èˆ‡æ¨ç†ã€‚

#### æ ¸å¿ƒå„ªå‹¢

- **é€Ÿåº¦æå‡**: 2-5x æ›´å¿«çš„è¨“ç·´é€Ÿåº¦
- **è¨˜æ†¶é«”å„ªåŒ–**: 40-70% æ›´å°‘çš„è¨˜æ†¶é«”ä½¿ç”¨
- **æ˜“ç”¨æ€§**: èˆ‡ Hugging Face Transformers å®Œç¾æ•´åˆ
- **æˆæœ¬æ•ˆç›Š**: é™ä½ GPU æˆæœ¬ï¼Œæ”¯æ´æ›´é•·çš„ä¸Šä¸‹æ–‡

### 2.2 Unsloth æ”¯æ´ DeepSeek-OCR çš„åŸç†

#### 2.2.1 æ¨¡å‹å°è£èˆ‡å„ªåŒ–

Unsloth ç‚º DeepSeek-OCR æä¾›äº†å°ˆé–€çš„å°è£é¡ `FastVisionModel`ï¼š

```python
from unsloth import FastVisionModel

# Unsloth å°è£çš„ DeepSeek-OCR
model, tokenizer = FastVisionModel.from_pretrained(
    "unsloth/DeepSeek-OCR",
    load_in_4bit=False,
    trust_remote_code=True,
)
```

**å°è£å„ªå‹¢**:

1. **è‡ªå‹•å„ªåŒ–**: è‡ªå‹•æ‡‰ç”¨å„ç¨®å„ªåŒ–æŠ€è¡“
2. **çµ±ä¸€æ¥å£**: æä¾›ä¸€è‡´çš„ API
3. **è¨˜æ†¶é«”ç®¡ç†**: æ™ºèƒ½ç®¡ç† GPU è¨˜æ†¶é«”
4. **éŒ¯èª¤è™•ç†**: å®Œå–„çš„éŒ¯èª¤æª¢æ¸¬èˆ‡è™•ç†

#### 2.2.2 Kernel å±¤ç´šå„ªåŒ–

Unsloth åœ¨ CUDA kernel å±¤ç´šé€²è¡Œäº†æ·±åº¦å„ªåŒ–ï¼š

```
æ¨™æº– PyTorch æµç¨‹:
Python API â†’ PyTorch C++ â†’ CUDA Kernels â†’ GPU

Unsloth å„ªåŒ–æµç¨‹:
Python API â†’ Unsloth Optimized Kernels â†’ GPU
              â†‘
         (è·³éä¸­é–“å±¤ï¼Œç›´æ¥å„ªåŒ–)
```

**å„ªåŒ–æŠ€è¡“**:

1. **Fused Kernels**: èåˆå¤šå€‹æ“ä½œç‚ºå–®ä¸€ kernel
   ```
   æ¨™æº–: Attention â†’ Add â†’ LayerNorm (3 å€‹ kernel)
   Unsloth: FusedAttentionNorm (1 å€‹ kernel)
   ```

2. **Memory Access Pattern å„ªåŒ–**
   - æ¸›å°‘å…¨å±€è¨˜æ†¶é«”è¨ªå•
   - æœ€å¤§åŒ–å…±äº«è¨˜æ†¶é«”ä½¿ç”¨
   - å„ªåŒ–è¨˜æ†¶é«”å°é½Š

3. **Flash Attention æ•´åˆ**
   ```python
   # Unsloth è‡ªå‹•å•Ÿç”¨ Flash Attention
   # O(NÂ²) â†’ O(N) è¨˜æ†¶é«”è¤‡é›œåº¦
   ```

#### 2.2.3 è¦–è¦ºæ¨¡å‹ç‰¹å®šå„ªåŒ–

DeepSeek-OCR ä½œç‚ºè¦–è¦ºèªè¨€æ¨¡å‹ï¼ŒUnsloth æä¾›äº†ç‰¹æ®Šå„ªåŒ–ï¼š

##### Image Preprocessing åŠ é€Ÿ

```python
# æ¨™æº–æ–¹å¼
image = Image.open("document.png")
inputs = processor(images=image, return_tensors="pt")

# Unsloth å„ªåŒ–
# è‡ªå‹•æ‡‰ç”¨ï¼š
# - GPU åŠ é€Ÿçš„åœ–åƒè®Šæ›
# - æ‰¹æ¬¡è™•ç†å„ªåŒ–
# - è¨˜æ†¶é«”æ± ç®¡ç†
```

##### Vision Encoder å„ªåŒ–

```python
class OptimizedVisionEncoder:
    def __init__(self):
        # Patch Embedding å„ªåŒ–
        self.patch_embed = FusedPatchEmbedding()
        
        # Attention å±¤å„ªåŒ–
        self.attention_layers = [
            FlashAttention() for _ in range(num_layers)
        ]
        
        # Compression å±¤å„ªåŒ–
        self.compression = OptimizedCompression()
```

### 2.3 Unsloth çš„å„ªåŒ–æ–¹æ³•

#### 2.3.1 è‡ªå‹•æ··åˆç²¾åº¦ (AMP)

Unsloth æ™ºèƒ½ç®¡ç†æ··åˆç²¾åº¦è¨ˆç®—ï¼š

```python
# è‡ªå‹•é¸æ“‡æœ€ä½³ç²¾åº¦
FP32: é«˜ç²¾åº¦è¨ˆç®—ï¼ˆå¦‚ LayerNormï¼‰
BF16: ä¸»è¦è¨ˆç®—ï¼ˆå¦‚ Attentionï¼‰
FP16: å¿«é€Ÿè¨ˆç®—ï¼ˆå¦‚ Activationï¼‰
INT8: æ¨ç†å„ªåŒ–ï¼ˆå¯é¸ï¼‰
```

**BFloat16 å„ªå‹¢**:
- èˆ‡ FP32 ç›¸åŒçš„å‹•æ…‹ç¯„åœ
- è¨“ç·´ç©©å®šæ€§æ›´å¥½
- RTX 30/40 ç³»åˆ—åŸç”Ÿæ”¯æ´

#### 2.3.2 Gradient Checkpointing å¢å¼·

```python
# æ¨™æº– Gradient Checkpointing
model.gradient_checkpointing_enable()
# è¨˜æ†¶é«”: â†“50%, é€Ÿåº¦: â†“30%

# Unsloth Gradient Checkpointing
use_gradient_checkpointing = "unsloth"
# è¨˜æ†¶é«”: â†“50%, é€Ÿåº¦: â†“10% (å„ªåŒ–å¾Œ)
```

**å„ªåŒ–åŸç†**:
- é¸æ“‡æ€§é‡è¨ˆç®—ï¼ˆåªé‡è¨ˆç®—æ˜‚è²´çš„å±¤ï¼‰
- æ™ºèƒ½ checkpoint é»é¸æ“‡
- ä¸¦è¡ŒåŒ–é‡è¨ˆç®—

#### 2.3.3 LoRA (Low-Rank Adaptation) å„ªåŒ–

Unsloth å° LoRA å¾®èª¿æä¾›ç‰¹åˆ¥å„ªåŒ–ï¼š

```python
from unsloth import FastVisionModel

# è‡ªå‹•æ‡‰ç”¨ LoRA
model = FastVisionModel.from_pretrained(
    "unsloth/DeepSeek-OCR",
    load_in_4bit=True,  # 4-bit é‡åŒ–
)

# Unsloth è‡ªå‹•å„ªåŒ–çš„ LoRA
model = FastVisionModel.get_peft_model(
    model,
    r=16,              # LoRA rank
    lora_alpha=16,
    target_modules=[   # è‡ªå‹•é¸æ“‡æœ€ä½³ç›®æ¨™æ¨¡çµ„
        "q_proj", "k_proj", "v_proj",
        "o_proj", "gate_proj", "up_proj"
    ],
)
```

**LoRA å„ªåŒ–æ•ˆæœ**:
- è¨“ç·´åƒæ•¸: â†“99% (åªè¨“ç·´ 1% çš„åƒæ•¸)
- è¨˜æ†¶é«”: â†“70%
- é€Ÿåº¦: â†‘2x
- æº–ç¢ºåº¦: ä¿æŒ > 95%

### 2.4 æ€§èƒ½å°æ¯”

#### æ¨ç†æ€§èƒ½

| æ–¹æ³• | é€Ÿåº¦ (it/s) | è¨˜æ†¶é«” (GB) | Token/s |
|------|-------------|-------------|---------|
| æ¨™æº– Transformers | 1.0 | 24.0 | 15 |
| + Flash Attention | 1.4 | 24.0 | 21 |
| + Unsloth | **2.1** | **16.8** | **32** |

#### è¨“ç·´æ€§èƒ½

| æ–¹æ³• | è¨“ç·´æ™‚é–“ | è¨˜æ†¶é«” | æº–ç¢ºåº¦ |
|------|----------|--------|--------|
| æ¨™æº–å…¨é‡å¾®èª¿ | 100 å°æ™‚ | 48 GB | 100% |
| LoRA | 24 å°æ™‚ | 16 GB | 98% |
| Unsloth LoRA | **17 å°æ™‚** | **10 GB** | **98%** |

### 2.5 Unsloth æŠ€è¡“æ¶æ§‹

```
Unsloth æ¶æ§‹å±¤æ¬¡:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User Application             â”‚
â”‚    (DeepSeek-OCR Flask API)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Unsloth Python API              â”‚
â”‚  - FastVisionModel                   â”‚
â”‚  - FastLanguageModel                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Unsloth Optimization Layer        â”‚
â”‚  - Kernel Fusion                     â”‚
â”‚  - Memory Management                 â”‚
â”‚  - Precision Control                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Transformers Integration         â”‚
â”‚  - Model Loading                     â”‚
â”‚  - Tokenization                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       PyTorch Backend                â”‚
â”‚  - CUDA Operations                   â”‚
â”‚  - Tensor Operations                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           GPU Hardware               â”‚
â”‚  (NVIDIA RTX 3090, A100, etc.)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ç³»çµ±å®‰è£èˆ‡ç’°å¢ƒè¨­å®š

### 3.1 ç³»çµ±éœ€æ±‚

#### ç¡¬é«”éœ€æ±‚

##### æœ€ä½é…ç½®
- **GPU**: NVIDIA GPU (8GB VRAM)
  - GTX 1080 Ti
  - RTX 2080
  - Tesla P40
- **RAM**: 16GB ç³»çµ±è¨˜æ†¶é«”
- **å„²å­˜**: 20GB å¯ç”¨ç©ºé–“
- **CPU**: 4 æ ¸å¿ƒä»¥ä¸Š

##### æ¨è–¦é…ç½®
- **GPU**: NVIDIA GPU (16GB+ VRAM)
  - RTX 3090 (24GB)
  - RTX 4090 (24GB)
  - A100 (40GB/80GB)
- **RAM**: 32GB+ ç³»çµ±è¨˜æ†¶é«”
- **å„²å­˜**: 50GB+ SSD
- **CPU**: 8 æ ¸å¿ƒä»¥ä¸Š

##### æ”¯æ´çš„ GPU æ¶æ§‹
- **Ampere**: RTX 30 ç³»åˆ—, A100
- **Ada Lovelace**: RTX 40 ç³»åˆ—
- **Turing**: RTX 20 ç³»åˆ—
- **Pascal**: GTX 10 ç³»åˆ— (æœ‰é™æ”¯æ´)

#### è»Ÿé«”éœ€æ±‚

- **ä½œæ¥­ç³»çµ±**: Linux (Ubuntu 20.04/22.04/24.04 æ¨è–¦)
- **Python**: 3.8, 3.9, 3.10, 3.11
- **CUDA**: 11.8, 12.1, 12.2, 12.8
- **NVIDIA Driver**: é©…å‹•ç‰ˆæœ¬ >= 525

### 3.2 ç’°å¢ƒå®‰è£æ­¥é©Ÿ

#### æ­¥é©Ÿ 1: ç³»çµ±æº–å‚™

```bash
# æ›´æ–°ç³»çµ±å¥—ä»¶
sudo apt update && sudo apt upgrade -y

# å®‰è£åŸºç¤å·¥å…·
sudo apt install -y build-essential git wget curl

# å®‰è£ Python é–‹ç™¼å¥—ä»¶
sudo apt install -y python3-dev python3-pip python3-venv
```

#### æ­¥é©Ÿ 2: å®‰è£ NVIDIA é©…å‹•å’Œ CUDA

##### æ–¹æ³• A: ä½¿ç”¨ Ubuntu å¥—ä»¶ç®¡ç†å™¨ï¼ˆæ¨è–¦ï¼‰

```bash
# å®‰è£ NVIDIA é©…å‹•å·¥å…·
sudo apt install ubuntu-drivers-common

# è‡ªå‹•å®‰è£æ¨è–¦é©…å‹•
sudo ubuntu-drivers autoinstall

# é‡æ–°å•Ÿå‹•
sudo reboot
```

é‡å•Ÿå¾Œé©—è­‰ï¼š

```bash
# æª¢æŸ¥ NVIDIA é©…å‹•
nvidia-smi

# æ‡‰è©²çœ‹åˆ°é¡ä¼¼è¼¸å‡ºï¼š
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 535.xx.xx    Driver Version: 535.xx.xx    CUDA Version: 12.2   |
# +-----------------------------------------------------------------------------+
```

##### æ–¹æ³• B: æ‰‹å‹•å®‰è£ç‰¹å®šç‰ˆæœ¬

```bash
# å®‰è£ NVIDIA é©…å‹• 535
sudo apt install -y nvidia-driver-535

# å®‰è£ CUDA Toolkit
sudo apt install -y nvidia-cuda-toolkit

# é‡æ–°å•Ÿå‹•
sudo reboot
```

#### æ­¥é©Ÿ 3: å‰µå»º Python è™›æ“¬ç’°å¢ƒ

```bash
# é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /GPUData/working/Deepseek-OCR

# å‰µå»ºè™›æ“¬ç’°å¢ƒ
python3 -m venv .venv

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
source .venv/bin/activate

# å‡ç´š pip
pip install --upgrade pip setuptools wheel
```

#### æ­¥é©Ÿ 4: å®‰è£ PyTorch (CUDA ç‰ˆæœ¬)

```bash
# For CUDA 12.1 (æ¨è–¦)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# For CUDA 11.8
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# é©—è­‰å®‰è£
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA:', torch.cuda.is_available())"
```

é æœŸè¼¸å‡ºï¼š
```
PyTorch: 2.8.0+cu121
CUDA: True
```

#### æ­¥é©Ÿ 5: å®‰è£ Unsloth

```bash
# å®‰è£ Unsloth
pip install --upgrade unsloth

# æˆ–å¼·åˆ¶é‡æ–°å®‰è£
pip install --upgrade --force-reinstall --no-deps --no-cache-dir unsloth unsloth_zoo
```

#### æ­¥é©Ÿ 6: å®‰è£å…¶ä»–ä¾è³´

```bash
# å®‰è£ Flask å’Œç›¸é—œå¥—ä»¶
pip install Flask Pillow Werkzeug

# å®‰è£ Transformers å’Œ HuggingFace å¥—ä»¶
pip install transformers accelerate huggingface_hub

# å®‰è£é¡å¤–å·¥å…·
pip install datasets peft bitsandbytes
```

#### æ­¥é©Ÿ 7: ä¸‹è¼‰ DeepSeek-OCR æ¨¡å‹

```bash
# æ–¹æ³• 1: ä½¿ç”¨ Git LFS (æ¨è–¦)
git lfs install
git clone https://huggingface.co/unsloth/DeepSeek-OCR ./deepseek_ocr

# æ–¹æ³• 2: ä½¿ç”¨ Python
python -c "from huggingface_hub import snapshot_download; snapshot_download('unsloth/DeepSeek-OCR', local_dir='./deepseek_ocr')"
```

æ¨¡å‹å¤§å°ï¼šç´„ 6.3 GB

#### æ­¥é©Ÿ 8: é©—è­‰å®‰è£

å‰µå»ºæ¸¬è©¦è…³æœ¬ `verify_installation.py`:

```python
#!/usr/bin/env python
"""é©—è­‰ DeepSeek-OCR ç’°å¢ƒå®‰è£"""

import sys

def check_cuda():
    """æª¢æŸ¥ CUDA"""
    import torch
    print("=" * 60)
    print("CUDA æª¢æŸ¥")
    print("=" * 60)
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  è¨˜æ†¶é«”: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB")
    return torch.cuda.is_available()

def check_unsloth():
    """æª¢æŸ¥ Unsloth"""
    print("\n" + "=" * 60)
    print("Unsloth æª¢æŸ¥")
    print("=" * 60)
    try:
        import unsloth
        print(f"âœ… Unsloth å·²å®‰è£")
        print(f"ç‰ˆæœ¬: {unsloth.__version__}")
        return True
    except ImportError as e:
        print(f"âŒ Unsloth æœªå®‰è£: {e}")
        return False

def check_transformers():
    """æª¢æŸ¥ Transformers"""
    print("\n" + "=" * 60)
    print("Transformers æª¢æŸ¥")
    print("=" * 60)
    try:
        import transformers
        print(f"âœ… Transformers å·²å®‰è£")
        print(f"ç‰ˆæœ¬: {transformers.__version__}")
        return True
    except ImportError as e:
        print(f"âŒ Transformers æœªå®‰è£: {e}")
        return False

def check_model():
    """æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ"""
    print("\n" + "=" * 60)
    print("æ¨¡å‹æª”æ¡ˆæª¢æŸ¥")
    print("=" * 60)
    import os
    model_path = "./deepseek_ocr"
    if os.path.exists(model_path):
        print(f"âœ… æ¨¡å‹ç›®éŒ„å­˜åœ¨: {model_path}")
        # æª¢æŸ¥é—œéµæª”æ¡ˆ
        files = ["config.json", "model-00001-of-000001.safetensors"]
        for f in files:
            file_path = os.path.join(model_path, f)
            if os.path.exists(file_path):
                size = os.path.getsize(file_path) / 1e9
                print(f"  âœ… {f}: {size:.2f} GB")
            else:
                print(f"  âŒ {f}: ä¸å­˜åœ¨")
                return False
        return True
    else:
        print(f"âŒ æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: {model_path}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "=" * 60)
    print("DeepSeek-OCR ç’°å¢ƒé©—è­‰")
    print("=" * 60 + "\n")
    
    checks = {
        "CUDA": check_cuda(),
        "Unsloth": check_unsloth(),
        "Transformers": check_transformers(),
        "Model": check_model(),
    }
    
    print("\n" + "=" * 60)
    print("é©—è­‰çµæœ")
    print("=" * 60)
    
    all_passed = True
    for name, passed in checks.items():
        status = "âœ… é€šé" if passed else "âŒ å¤±æ•—"
        print(f"{name:15s}: {status}")
        if not passed:
            all_passed = False
    
    print("=" * 60)
    
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼ç³»çµ±å·²æº–å‚™å°±ç·’ã€‚")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤è¨Šæ¯ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

åŸ·è¡Œé©—è­‰ï¼š

```bash
python verify_installation.py
```

### 3.3 ç’°å¢ƒé…ç½®

#### é…ç½®æ–‡ä»¶

å‰µå»º `.env` æª”æ¡ˆé€²è¡Œç’°å¢ƒé…ç½®ï¼š

```bash
# .env - ç’°å¢ƒè®Šæ•¸é…ç½®

# Flask é…ç½®
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=False

# æ¨¡å‹é…ç½®
MODEL_NAME=unsloth/DeepSeek-OCR
MODEL_DIR=./deepseek_ocr
LOAD_IN_4BIT=False

# Unsloth é…ç½®
UNSLOTH_WARN_UNINITIALIZED=0
HF_HUB_OFFLINE=1
TRANSFORMERS_TRUST_REMOTE_CODE=1

# OCR åƒæ•¸
OCR_BASE_SIZE=1024
OCR_IMAGE_SIZE=640
OCR_CROP_MODE=True

# æª”æ¡ˆé…ç½®
MAX_UPLOAD_SIZE=16777216  # 16MB
UPLOAD_FOLDER=uploads
ALLOWED_EXTENSIONS=png,jpg,jpeg,gif,bmp,webp
```

#### ç³»çµ±æœå‹™é…ç½®ï¼ˆSystemdï¼‰

å‰µå»ºç³»çµ±æœå‹™ `/etc/systemd/system/deepseek-ocr.service`:

```ini
[Unit]
Description=DeepSeek-OCR API Service
After=network.target

[Service]
Type=simple
User=your_username
WorkingDirectory=/GPUData/working/Deepseek-OCR
Environment="PATH=/GPUData/working/Deepseek-OCR/.venv/bin"
EnvironmentFile=/GPUData/working/Deepseek-OCR/.env
ExecStart=/GPUData/working/Deepseek-OCR/.venv/bin/python app.py
Restart=always
RestartSec=10

# è³‡æºé™åˆ¶
MemoryLimit=32G
CPUQuota=400%

[Install]
WantedBy=multi-user.target
```

å•Ÿå‹•æœå‹™ï¼š

```bash
# é‡æ–°è¼‰å…¥ systemd
sudo systemctl daemon-reload

# å•Ÿç”¨æœå‹™
sudo systemctl enable deepseek-ocr

# å•Ÿå‹•æœå‹™
sudo systemctl start deepseek-ocr

# æª¢æŸ¥ç‹€æ…‹
sudo systemctl status deepseek-ocr

# æŸ¥çœ‹æ—¥èªŒ
sudo journalctl -u deepseek-ocr -f
```

### 3.4 ç–‘é›£æ’è§£

#### å•é¡Œ 1: GPU åµæ¸¬å¤±æ•—

```bash
# æª¢æŸ¥ NVIDIA é©…å‹•
nvidia-smi

# å¦‚æœå¤±æ•—ï¼Œé‡æ–°å®‰è£é©…å‹•
sudo apt purge nvidia-*
sudo apt autoremove
sudo ubuntu-drivers autoinstall
sudo reboot
```

#### å•é¡Œ 2: CUDA ç‰ˆæœ¬ä¸åŒ¹é…

```bash
# æª¢æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# å®‰è£å°æ‡‰çš„ PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu<version>
```

#### å•é¡Œ 3: è¨˜æ†¶é«”ä¸è¶³

```python
# ä½¿ç”¨ 4-bit é‡åŒ–
model = FastVisionModel.from_pretrained(
    model_dir,
    load_in_4bit=True,  # é™ä½è¨˜æ†¶é«”ä½¿ç”¨
)
```

---

## 4. API ä½¿ç”¨æŒ‡å—èˆ‡æ‡‰ç”¨é ˜åŸŸ

### 4.1 å¿«é€Ÿé–‹å§‹

#### 4.1.1 å•Ÿå‹•æœå‹™

```bash
# é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /GPUData/working/Deepseek-OCR

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
source .venv/bin/activate

# å•Ÿå‹•æœå‹™
python app.py
```

æœå‹™å°‡åœ¨ `http://0.0.0.0:5000` ä¸Šé‹è¡Œã€‚

#### 4.1.2 ç¬¬ä¸€å€‹ API è«‹æ±‚

```bash
# å¥åº·æª¢æŸ¥
curl http://localhost:5000/health

# OCR è¾¨è­˜
curl -X POST \
  -F "file=@document.png" \
  http://localhost:5000/ocr
```

### 4.2 API ç«¯é»è©³è§£

#### 4.2.1 å¥åº·æª¢æŸ¥ API

**ç«¯é»**: `GET /health`

**ç”¨é€”**: æª¢æŸ¥æœå‹™æ˜¯å¦æ­£å¸¸é‹è¡Œ

**è«‹æ±‚ç¯„ä¾‹**:
```bash
curl http://localhost:5000/health
```

**å›æ‡‰ç¯„ä¾‹**:
```json
{
  "status": "healthy",
  "service": "DeepSeek-OCR API",
  "timestamp": "2025-11-10T15:30:00.123456"
}
```

#### 4.2.2 å–®å¼µåœ–ç‰‡ OCR API

**ç«¯é»**: `POST /ocr`

**ç”¨é€”**: å°å–®å¼µåœ–ç‰‡åŸ·è¡Œ OCR è¾¨è­˜

**è«‹æ±‚åƒæ•¸**:
- `file` (å¿…å¡«): åœ–ç‰‡æª”æ¡ˆ
- `prompt` (é¸å¡«): è‡ªè¨‚æç¤ºè©

**è«‹æ±‚ç¯„ä¾‹**:
```bash
# åŸºæœ¬ä½¿ç”¨
curl -X POST \
  -F "file=@invoice.png" \
  http://localhost:5000/ocr

# ä½¿ç”¨è‡ªè¨‚æç¤ºè©
curl -X POST \
  -F "file=@table.png" \
  -F "prompt=<image>\nè«‹æå–é€™å€‹è¡¨æ ¼çš„æ‰€æœ‰æ•¸æ“šï¼Œä¿æŒæ ¼å¼ã€‚" \
  http://localhost:5000/ocr
```

**å›æ‡‰ç¯„ä¾‹**:
```json
{
  "text": "ç™¼ç¥¨\nå…¬å¸åç¨±ï¼šXXXæœ‰é™å…¬å¸\nçµ±ä¸€ç·¨è™Ÿï¼š12345678\n...",
  "image_path": "uploads/20251110_153000_invoice.png",
  "prompt": "<image>\nFree OCR."
}
```

**éŒ¯èª¤å›æ‡‰**:
```json
{
  "error": "ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹ã€‚å…è¨±çš„é¡å‹: png, jpg, jpeg, gif, bmp, webp"
}
```

#### 4.2.3 æ‰¹æ¬¡åœ–ç‰‡ OCR API

**ç«¯é»**: `POST /ocr/batch`

**ç”¨é€”**: å°å¤šå¼µåœ–ç‰‡åŸ·è¡Œæ‰¹æ¬¡ OCR è¾¨è­˜

**è«‹æ±‚åƒæ•¸**:
- `files` (å¿…å¡«): å¤šå€‹åœ–ç‰‡æª”æ¡ˆ
- `prompt` (é¸å¡«): è‡ªè¨‚æç¤ºè©ï¼ˆæ‡‰ç”¨æ–¼æ‰€æœ‰åœ–ç‰‡ï¼‰

**è«‹æ±‚ç¯„ä¾‹**:
```bash
curl -X POST \
  -F "files=@page1.png" \
  -F "files=@page2.png" \
  -F "files=@page3.png" \
  http://localhost:5000/ocr/batch
```

**å›æ‡‰ç¯„ä¾‹**:
```json
{
  "results": [
    {
      "text": "ç¬¬ä¸€é å…§å®¹...",
      "image_path": "uploads/20251110_153000_0_page1.png",
      "prompt": "<image>\nFree OCR."
    },
    {
      "text": "ç¬¬äºŒé å…§å®¹...",
      "image_path": "uploads/20251110_153000_1_page2.png",
      "prompt": "<image>\nFree OCR."
    }
  ],
  "total": 2
}
```

### 4.3 ç·¨ç¨‹èªè¨€ç¯„ä¾‹

#### 4.3.1 Python ç¯„ä¾‹

##### åŸºæœ¬ä½¿ç”¨

```python
import requests

def ocr_image(image_path, host="http://localhost:5000"):
    """åŸ·è¡Œ OCR è¾¨è­˜"""
    url = f"{host}/ocr"
    
    with open(image_path, 'rb') as f:
        files = {'file': f}
        response = requests.post(url, files=files)
    
    if response.status_code == 200:
        result = response.json()
        return result['text']
    else:
        error = response.json()
        raise Exception(f"OCR å¤±æ•—: {error.get('error')}")

# ä½¿ç”¨ç¯„ä¾‹
text = ocr_image("document.png")
print(text)
```

##### æ‰¹æ¬¡è™•ç†

```python
import requests
from pathlib import Path

def batch_ocr(image_paths, host="http://localhost:5000"):
    """æ‰¹æ¬¡ OCR è¾¨è­˜"""
    url = f"{host}/ocr/batch"
    
    files = []
    for path in image_paths:
        files.append(('files', open(path, 'rb')))
    
    try:
        response = requests.post(url, files=files)
        
        if response.status_code == 200:
            return response.json()['results']
        else:
            raise Exception(f"æ‰¹æ¬¡ OCR å¤±æ•—: {response.json().get('error')}")
    finally:
        # é—œé–‰æ‰€æœ‰æª”æ¡ˆ
        for _, f in files:
            f.close()

# æ‰¹æ¬¡è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡
image_dir = Path("documents")
image_files = list(image_dir.glob("*.png"))

results = batch_ocr(image_files)
for i, result in enumerate(results):
    print(f"æ–‡ä»¶ {i+1}:\n{result['text']}\n")
```

##### å®Œæ•´çš„é¡åˆ¥å°è£

```python
import requests
from typing import List, Dict, Optional
from pathlib import Path

class DeepSeekOCRClient:
    """DeepSeek-OCR API å®¢æˆ¶ç«¯"""
    
    def __init__(self, host: str = "http://localhost:5000"):
        self.host = host
        self.session = requests.Session()
    
    def health_check(self) -> bool:
        """æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹"""
        try:
            response = self.session.get(f"{self.host}/health")
            return response.status_code == 200
        except Exception:
            return False
    
    def ocr(
        self, 
        image_path: str, 
        prompt: Optional[str] = None
    ) -> Dict[str, str]:
        """å–®å¼µåœ–ç‰‡ OCR"""
        url = f"{self.host}/ocr"
        
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {'prompt': prompt} if prompt else {}
            
            response = self.session.post(url, files=files, data=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"OCR å¤±æ•—: {response.json().get('error')}")
    
    def batch_ocr(
        self, 
        image_paths: List[str], 
        prompt: Optional[str] = None
    ) -> List[Dict[str, str]]:
        """æ‰¹æ¬¡åœ–ç‰‡ OCR"""
        url = f"{self.host}/ocr/batch"
        
        files = [('files', open(path, 'rb')) for path in image_paths]
        data = {'prompt': prompt} if prompt else {}
        
        try:
            response = self.session.post(url, files=files, data=data)
            
            if response.status_code == 200:
                return response.json()['results']
            else:
                raise Exception(f"æ‰¹æ¬¡ OCR å¤±æ•—: {response.json().get('error')}")
        finally:
            for _, f in files:
                f.close()
    
    def ocr_directory(
        self, 
        directory: str, 
        pattern: str = "*.png",
        prompt: Optional[str] = None
    ) -> Dict[str, str]:
        """è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡"""
        dir_path = Path(directory)
        image_files = sorted(dir_path.glob(pattern))
        
        if not image_files:
            raise ValueError(f"ç›®éŒ„ {directory} ä¸­æ²’æœ‰æ‰¾åˆ°åŒ¹é… {pattern} çš„æª”æ¡ˆ")
        
        results = self.batch_ocr([str(f) for f in image_files], prompt)
        
        # å»ºç«‹æª”æ¡ˆååˆ°çµæœçš„æ˜ å°„
        return {
            image_files[i].name: results[i]['text']
            for i in range(len(results))
        }

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    client = DeepSeekOCRClient()
    
    # å¥åº·æª¢æŸ¥
    if not client.health_check():
        print("æœå‹™æœªé‹è¡Œï¼")
        exit(1)
    
    # å–®å¼µåœ–ç‰‡
    result = client.ocr("document.png")
    print(f"OCR çµæœ:\n{result['text']}\n")
    
    # æ‰¹æ¬¡è™•ç†
    results = client.batch_ocr([
        "page1.png", 
        "page2.png", 
        "page3.png"
    ])
    
    for i, result in enumerate(results, 1):
        print(f"é é¢ {i}:\n{result['text']}\n")
    
    # è™•ç†æ•´å€‹ç›®éŒ„
    dir_results = client.ocr_directory("documents", "*.jpg")
    for filename, text in dir_results.items():
        print(f"{filename}:\n{text}\n")
```

#### 4.3.2 JavaScript/TypeScript ç¯„ä¾‹

##### Node.js ç¯„ä¾‹

```javascript
const FormData = require('form-data');
const fs = require('fs');
const axios = require('axios');

class DeepSeekOCRClient {
    constructor(host = 'http://localhost:5000') {
        this.host = host;
    }

    async healthCheck() {
        try {
            const response = await axios.get(`${this.host}/health`);
            return response.status === 200;
        } catch (error) {
            return false;
        }
    }

    async ocr(imagePath, prompt = null) {
        const form = new FormData();
        form.append('file', fs.createReadStream(imagePath));
        if (prompt) {
            form.append('prompt', prompt);
        }

        const response = await axios.post(
            `${this.host}/ocr`,
            form,
            { headers: form.getHeaders() }
        );

        return response.data;
    }

    async batchOcr(imagePaths, prompt = null) {
        const form = new FormData();
        
        imagePaths.forEach(path => {
            form.append('files', fs.createReadStream(path));
        });
        
        if (prompt) {
            form.append('prompt', prompt);
        }

        const response = await axios.post(
            `${this.host}/ocr/batch`,
            form,
            { headers: form.getHeaders() }
        );

        return response.data.results;
    }
}

// ä½¿ç”¨ç¯„ä¾‹
async function main() {
    const client = new DeepSeekOCRClient();

    // å¥åº·æª¢æŸ¥
    if (!await client.healthCheck()) {
        console.log('æœå‹™æœªé‹è¡Œï¼');
        return;
    }

    // å–®å¼µåœ–ç‰‡
    const result = await client.ocr('document.png');
    console.log('OCR çµæœ:');
    console.log(result.text);

    // æ‰¹æ¬¡è™•ç†
    const results = await client.batchOcr([
        'page1.png',
        'page2.png',
        'page3.png'
    ]);

    results.forEach((result, index) => {
        console.log(`\né é¢ ${index + 1}:`);
        console.log(result.text);
    });
}

main().catch(console.error);
```

##### ç€è¦½å™¨ç¯„ä¾‹ (React)

```typescript
import React, { useState } from 'react';
import axios from 'axios';

interface OCRResult {
    text: string;
    image_path: string;
    prompt: string;
}

const OCRComponent: React.FC = () => {
    const [file, setFile] = useState<File | null>(null);
    const [result, setResult] = useState<string>('');
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState<string>('');

    const API_HOST = 'http://localhost:5000';

    const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        if (e.target.files && e.target.files[0]) {
            setFile(e.target.files[0]);
            setError('');
        }
    };

    const handleSubmit = async (e: React.FormEvent) => {
        e.preventDefault();
        
        if (!file) {
            setError('è«‹é¸æ“‡åœ–ç‰‡æª”æ¡ˆ');
            return;
        }

        setLoading(true);
        setError('');
        setResult('');

        const formData = new FormData();
        formData.append('file', file);

        try {
            const response = await axios.post<OCRResult>(
                `${API_HOST}/ocr`,
                formData,
                {
                    headers: {
                        'Content-Type': 'multipart/form-data',
                    },
                }
            );

            setResult(response.data.text);
        } catch (err: any) {
            setError(
                err.response?.data?.error || 
                'OCR è¾¨è­˜å¤±æ•—ï¼Œè«‹é‡è©¦'
            );
        } finally {
            setLoading(false);
        }
    };

    return (
        <div className="ocr-container">
            <h2>DeepSeek-OCR æ–‡å­—è¾¨è­˜</h2>
            
            <form onSubmit={handleSubmit}>
                <input
                    type="file"
                    accept="image/*"
                    onChange={handleFileChange}
                    disabled={loading}
                />
                
                <button 
                    type="submit" 
                    disabled={!file || loading}
                >
                    {loading ? 'è¾¨è­˜ä¸­...' : 'é–‹å§‹è¾¨è­˜'}
                </button>
            </form>

            {error && (
                <div className="error">
                    éŒ¯èª¤: {error}
                </div>
            )}

            {result && (
                <div className="result">
                    <h3>è¾¨è­˜çµæœ:</h3>
                    <pre>{result}</pre>
                </div>
            )}
        </div>
    );
};

export default OCRComponent;
```

#### 4.3.3 å…¶ä»–èªè¨€ç¯„ä¾‹

##### cURL (Shell è…³æœ¬)

```bash
#!/bin/bash
# ocr.sh - DeepSeek-OCR Shell è…³æœ¬

API_HOST="http://localhost:5000"

# å¥åº·æª¢æŸ¥
health_check() {
    echo "æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹..."
    curl -s "${API_HOST}/health" | jq '.'
}

# å–®å¼µåœ–ç‰‡ OCR
ocr_single() {
    local image_file="$1"
    local prompt="$2"
    
    echo "è¾¨è­˜åœ–ç‰‡: ${image_file}"
    
    if [ -z "$prompt" ]; then
        curl -X POST \
            -F "file=@${image_file}" \
            "${API_HOST}/ocr" | jq -r '.text'
    else
        curl -X POST \
            -F "file=@${image_file}" \
            -F "prompt=${prompt}" \
            "${API_HOST}/ocr" | jq -r '.text'
    fi
}

# æ‰¹æ¬¡ OCR
ocr_batch() {
    local files=("$@")
    local curl_args=()
    
    echo "æ‰¹æ¬¡è¾¨è­˜ ${#files[@]} å¼µåœ–ç‰‡..."
    
    for file in "${files[@]}"; do
        curl_args+=(-F "files=@${file}")
    done
    
    curl -X POST \
        "${curl_args[@]}" \
        "${API_HOST}/ocr/batch" | jq '.results[].text'
}

# ä¸»å‡½æ•¸
main() {
    case "$1" in
        health)
            health_check
            ;;
        single)
            ocr_single "$2" "$3"
            ;;
        batch)
            shift
            ocr_batch "$@"
            ;;
        *)
            echo "ç”¨æ³•:"
            echo "  $0 health                    - å¥åº·æª¢æŸ¥"
            echo "  $0 single <åœ–ç‰‡>             - å–®å¼µ OCR"
            echo "  $0 single <åœ–ç‰‡> <æç¤ºè©>    - å–®å¼µ OCR (è‡ªè¨‚æç¤º)"
            echo "  $0 batch <åœ–ç‰‡1> <åœ–ç‰‡2> ... - æ‰¹æ¬¡ OCR"
            exit 1
            ;;
    esac
}

main "$@"
```

ä½¿ç”¨ç¯„ä¾‹:
```bash
chmod +x ocr.sh

# å¥åº·æª¢æŸ¥
./ocr.sh health

# å–®å¼µ OCR
./ocr.sh single document.png

# æ‰¹æ¬¡ OCR
./ocr.sh batch page1.png page2.png page3.png
```

### 4.4 æ‡‰ç”¨é ˜åŸŸèˆ‡å¯¦éš›æ¡ˆä¾‹

#### 4.4.1 æ–‡æª”æ•¸å­—åŒ–

##### æ‡‰ç”¨å ´æ™¯
- æ­·å²æ–‡ç»æ•¸å­—åŒ–
- åœ–æ›¸é¤¨æª”æ¡ˆç®¡ç†
- ä¼æ¥­æ–‡æª”ç®¡ç†
- ç´™è³ªåˆç´„é›»å­åŒ–

##### å¯¦æ–½æ–¹æ¡ˆ

```python
"""æ–‡æª”æ•¸å­—åŒ–ç³»çµ±"""
import os
from pathlib import Path
from deepseek_ocr_client import DeepSeekOCRClient

class DocumentDigitizer:
    """æ–‡æª”æ•¸å­—åŒ–å·¥å…·"""
    
    def __init__(self, ocr_host="http://localhost:5000"):
        self.client = DeepSeekOCRClient(ocr_host)
    
    def digitize_document(
        self, 
        input_dir: str, 
        output_dir: str,
        file_pattern: str = "*.jpg"
    ):
        """æ•¸å­—åŒ–æ•´å€‹æ–‡æª”ç›®éŒ„"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ç²å–æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
        image_files = sorted(input_path.glob(file_pattern))
        
        print(f"æ‰¾åˆ° {len(image_files)} å€‹åœ–ç‰‡æª”æ¡ˆ")
        
        # æ‰¹æ¬¡è™•ç†
        batch_size = 10
        all_results = []
        
        for i in range(0, len(image_files), batch_size):
            batch = image_files[i:i+batch_size]
            print(f"è™•ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(image_files)-1)//batch_size + 1}")
            
            results = self.client.batch_ocr([str(f) for f in batch])
            all_results.extend(zip(batch, results))
        
        # å„²å­˜çµæœ
        for image_file, result in all_results:
            # å»ºç«‹å°æ‡‰çš„æ–‡å­—æª”
            txt_file = output_path / f"{image_file.stem}.txt"
            with open(txt_file, 'w', encoding='utf-8') as f:
                f.write(result['text'])
            
            print(f"å·²è™•ç†: {image_file.name} -> {txt_file.name}")
        
        # åˆä½µæ‰€æœ‰æ–‡å­—ç‚ºå–®ä¸€æª”æ¡ˆ
        merged_file = output_path / "merged_document.txt"
        with open(merged_file, 'w', encoding='utf-8') as f:
            for _, result in all_results:
                f.write(result['text'])
                f.write("\n\n" + "="*80 + "\n\n")
        
        print(f"\nå®Œæˆï¼å…±è™•ç† {len(all_results)} å€‹æª”æ¡ˆ")
        print(f"åˆä½µæª”æ¡ˆ: {merged_file}")

# ä½¿ç”¨ç¯„ä¾‹
digitizer = DocumentDigitizer()
digitizer.digitize_document(
    input_dir="scanned_documents",
    output_dir="digitized_output",
    file_pattern="*.png"
)
```

##### ROI åˆ†æ
- **æ•ˆç‡æå‡**: æ¯”äººå·¥è¼¸å…¥å¿« 100-200 å€
- **æˆæœ¬ç¯€çœ**: é™ä½ 80% æ•¸æ“šè¼¸å…¥æˆæœ¬
- **æº–ç¢ºåº¦**: 97% æº–ç¢ºç‡ï¼Œæ¸›å°‘äººç‚ºéŒ¯èª¤
- **å¯æœå°‹æ€§**: æ‰€æœ‰æ–‡æª”è®Šç‚ºå¯æœå°‹çš„æ•¸å­—æ ¼å¼

#### 4.4.2 ç™¼ç¥¨èˆ‡æ”¶æ“šè™•ç†

##### æ‡‰ç”¨å ´æ™¯
- è²¡å‹™å ±éŠ·ç³»çµ±
- é›»å­å•†å‹™è¨‚å–®ç®¡ç†
- æœƒè¨ˆè‡ªå‹•åŒ–
- è²»ç”¨è¿½è¹¤

##### å¯¦æ–½æ–¹æ¡ˆ

```python
"""ç™¼ç¥¨è™•ç†ç³»çµ±"""
import re
from datetime import datetime
from typing import Dict, List

class InvoiceProcessor:
    """ç™¼ç¥¨è™•ç†å™¨"""
    
    def __init__(self, ocr_host="http://localhost:5000"):
        self.client = DeepSeekOCRClient(ocr_host)
    
    def process_invoice(self, image_path: str) -> Dict:
        """è™•ç†å–®å¼µç™¼ç¥¨"""
        # ä½¿ç”¨å°ˆé–€çš„æç¤ºè©
        prompt = """<image>
è«‹æå–é€™å¼µç™¼ç¥¨çš„ä»¥ä¸‹è³‡è¨Šï¼š
- ç™¼ç¥¨è™Ÿç¢¼
- æ—¥æœŸ
- å…¬å¸åç¨±
- çµ±ä¸€ç·¨è™Ÿ
- é …ç›®æ˜ç´°
- ç¸½é‡‘é¡
"""
        
        result = self.client.ocr(image_path, prompt)
        text = result['text']
        
        # è§£æç™¼ç¥¨è³‡è¨Š
        invoice_data = {
            'raw_text': text,
            'invoice_number': self._extract_invoice_number(text),
            'date': self._extract_date(text),
            'company_name': self._extract_company(text),
            'tax_id': self._extract_tax_id(text),
            'total_amount': self._extract_amount(text),
            'items': self._extract_items(text),
        }
        
        return invoice_data
    
    def _extract_invoice_number(self, text: str) -> str:
        """æå–ç™¼ç¥¨è™Ÿç¢¼"""
        pattern = r'ç™¼ç¥¨è™Ÿç¢¼[:ï¼š]\s*([A-Z]{2}\d{8})'
        match = re.search(pattern, text)
        return match.group(1) if match else ""
    
    def _extract_date(self, text: str) -> str:
        """æå–æ—¥æœŸ"""
        patterns = [
            r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})',
            r'(\d{3})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
        ]
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(0)
        return ""
    
    def _extract_company(self, text: str) -> str:
        """æå–å…¬å¸åç¨±"""
        pattern = r'([^ï¼Œã€‚\n]+(?:æœ‰é™å…¬å¸|è‚¡ä»½æœ‰é™å…¬å¸|ä¼æ¥­ç¤¾))'
        match = re.search(pattern, text)
        return match.group(1) if match else ""
    
    def _extract_tax_id(self, text: str) -> str:
        """æå–çµ±ä¸€ç·¨è™Ÿ"""
        pattern = r'çµ±ä¸€ç·¨è™Ÿ[:ï¼š]\s*(\d{8})'
        match = re.search(pattern, text)
        return match.group(1) if match else ""
    
    def _extract_amount(self, text: str) -> float:
        """æå–ç¸½é‡‘é¡"""
        patterns = [
            r'ç¸½[è¨ˆé‡‘]é¡[:ï¼š]\s*[\$NT]*\s*([\d,]+)',
            r'åˆè¨ˆ[:ï¼š]\s*[\$NT]*\s*([\d,]+)',
        ]
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                amount_str = match.group(1).replace(',', '')
                return float(amount_str)
        return 0.0
    
    def _extract_items(self, text: str) -> List[Dict]:
        """æå–é …ç›®æ˜ç´°"""
        # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰ç”¨éœ€è¦æ›´è¤‡é›œçš„è§£æ
        items = []
        lines = text.split('\n')
        
        for line in lines:
            # åŒ¹é…é …ç›®æ ¼å¼ï¼šåç¨± æ•¸é‡ å–®åƒ¹ é‡‘é¡
            pattern = r'(.+?)\s+(\d+)\s+([\d,]+)\s+([\d,]+)'
            match = re.search(pattern, line)
            if match:
                items.append({
                    'name': match.group(1).strip(),
                    'quantity': int(match.group(2)),
                    'unit_price': float(match.group(3).replace(',', '')),
                    'amount': float(match.group(4).replace(',', '')),
                })
        
        return items
    
    def batch_process_invoices(
        self, 
        invoice_dir: str,
        output_csv: str = "invoices.csv"
    ):
        """æ‰¹æ¬¡è™•ç†ç™¼ç¥¨ä¸¦è¼¸å‡º CSV"""
        import csv
        from pathlib import Path
        
        invoice_path = Path(invoice_dir)
        image_files = list(invoice_path.glob("*.png")) + \
                      list(invoice_path.glob("*.jpg"))
        
        processed_invoices = []
        
        for image_file in image_files:
            print(f"è™•ç†: {image_file.name}")
            try:
                invoice_data = self.process_invoice(str(image_file))
                invoice_data['filename'] = image_file.name
                processed_invoices.append(invoice_data)
            except Exception as e:
                print(f"  éŒ¯èª¤: {e}")
        
        # è¼¸å‡º CSV
        if processed_invoices:
            with open(output_csv, 'w', newline='', encoding='utf-8-sig') as f:
                fieldnames = [
                    'filename', 'invoice_number', 'date',
                    'company_name', 'tax_id', 'total_amount'
                ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for invoice in processed_invoices:
                    row = {k: invoice.get(k, '') for k in fieldnames}
                    writer.writerow(row)
            
            print(f"\nå®Œæˆï¼å·²è™•ç† {len(processed_invoices)} å¼µç™¼ç¥¨")
            print(f"çµæœå·²å„²å­˜è‡³: {output_csv}")

# ä½¿ç”¨ç¯„ä¾‹
processor = InvoiceProcessor()

# å–®å¼µç™¼ç¥¨
invoice_data = processor.process_invoice("invoice.png")
print(f"ç™¼ç¥¨è™Ÿç¢¼: {invoice_data['invoice_number']}")
print(f"ç¸½é‡‘é¡: ${invoice_data['total_amount']:,.2f}")

# æ‰¹æ¬¡è™•ç†
processor.batch_process_invoices("invoices", "processed_invoices.csv")
```

##### æ•ˆç›Š
- **è‡ªå‹•åŒ–**: æ¸›å°‘ 90% æ‰‹å‹•è¼¸å…¥æ™‚é–“
- **æ•´åˆ**: ç›´æ¥è¼¸å‡ºç‚º CSV/Excel æ ¼å¼
- **è¿½è¹¤**: å»ºç«‹å®Œæ•´çš„è²»ç”¨è¨˜éŒ„
- **åˆè¦**: ç¢ºä¿è²¡å‹™æ–‡æª”çš„æ•¸å­—åŒ–å­˜æª”

#### 4.4.3 è¡¨æ ¼æ•¸æ“šæå–

##### æ‡‰ç”¨å ´æ™¯
- è²¡å‹™å ±è¡¨åˆ†æ
- å•å·èª¿æŸ¥æ•¸æ“šæ•´ç†
- ç§‘å­¸å¯¦é©—æ•¸æ“šè¨˜éŒ„
- çµ±è¨ˆå ±å‘Šè™•ç†

##### å¯¦æ–½æ–¹æ¡ˆ

```python
"""è¡¨æ ¼æ•¸æ“šæå–ç³»çµ±"""
import pandas as pd
from typing import List

class TableExtractor:
    """è¡¨æ ¼æå–å™¨"""
    
    def __init__(self, ocr_host="http://localhost:5000"):
        self.client = DeepSeekOCRClient(ocr_host)
    
    def extract_table(
        self, 
        image_path: str,
        save_to_excel: bool = True
    ) -> pd.DataFrame:
        """æå–è¡¨æ ¼æ•¸æ“š"""
        # ä½¿ç”¨è¡¨æ ¼å°ˆç”¨æç¤ºè©
        prompt = """<image>
è«‹æå–é€™å€‹è¡¨æ ¼çš„æ‰€æœ‰æ•¸æ“šã€‚
è¼¸å‡ºæ ¼å¼ï¼šæ¯è¡Œç”¨æ›è¡Œç¬¦åˆ†éš”ï¼Œæ¯å€‹å–®å…ƒæ ¼ç”¨ | ç¬¦è™Ÿåˆ†éš”ã€‚
ä¿æŒè¡¨é ­å’Œæ•¸æ“šçš„å°æ‡‰é—œä¿‚ã€‚
"""
        
        result = self.client.ocr(image_path, prompt)
        text = result['text']
        
        # è§£æè¡¨æ ¼
        df = self._parse_table_text(text)
        
        # å„²å­˜ç‚º Excel
        if save_to_excel:
            output_file = image_path.replace('.png', '.xlsx').replace('.jpg', '.xlsx')
            df.to_excel(output_file, index=False)
            print(f"è¡¨æ ¼å·²å„²å­˜è‡³: {output_file}")
        
        return df
    
    def _parse_table_text(self, text: str) -> pd.DataFrame:
        """è§£æè¡¨æ ¼æ–‡å­—ç‚º DataFrame"""
        lines = text.strip().split('\n')
        
        # å˜—è©¦ä¸åŒçš„åˆ†éš”ç¬¦
        separators = ['|', '\t', '  ', ',']
        
        for sep in separators:
            if sep in lines[0]:
                # è§£ææ¯ä¸€è¡Œ
                rows = []
                for line in lines:
                    if line.strip():
                        cells = [cell.strip() for cell in line.split(sep)]
                        rows.append(cells)
                
                if rows:
                    # ç¬¬ä¸€è¡Œä½œç‚ºè¡¨é ­
                    df = pd.DataFrame(rows[1:], columns=rows[0])
                    return df
        
        # å¦‚æœç„¡æ³•è§£æï¼Œè¿”å›åŸå§‹æ–‡å­—
        return pd.DataFrame({'text': [text]})
    
    def batch_extract_tables(
        self,
        table_dir: str,
        output_dir: str = "extracted_tables"
    ):
        """æ‰¹æ¬¡æå–è¡¨æ ¼"""
        from pathlib import Path
        
        input_path = Path(table_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        image_files = list(input_path.glob("*.png")) + \
                      list(input_path.glob("*.jpg"))
        
        all_dataframes = {}
        
        for image_file in image_files:
            print(f"æå–è¡¨æ ¼: {image_file.name}")
            try:
                df = self.extract_table(str(image_file), save_to_excel=False)
                
                # å„²å­˜ç‚º Excel
                excel_file = output_path / f"{image_file.stem}.xlsx"
                df.to_excel(excel_file, index=False)
                
                all_dataframes[image_file.name] = df
                print(f"  æˆåŠŸ! è¡¨æ ¼å¤§å°: {df.shape}")
            except Exception as e:
                print(f"  éŒ¯èª¤: {e}")
        
        # å¦‚æœæ‰€æœ‰è¡¨æ ¼çµæ§‹ç›¸åŒï¼Œåˆä½µç‚ºå–®ä¸€æª”æ¡ˆ
        if all_dataframes:
            try:
                combined_df = pd.concat(all_dataframes.values(), ignore_index=True)
                combined_file = output_path / "all_tables_combined.xlsx"
                combined_df.to_excel(combined_file, index=False)
                print(f"\nåˆä½µæª”æ¡ˆ: {combined_file}")
            except Exception as e:
                print(f"\nç„¡æ³•åˆä½µè¡¨æ ¼: {e}")

# ä½¿ç”¨ç¯„ä¾‹
extractor = TableExtractor()

# å–®å€‹è¡¨æ ¼
df = extractor.extract_table("financial_report.png")
print(df.head())

# æ‰¹æ¬¡è™•ç†
extractor.batch_extract_tables("tables")
```

#### 4.4.4 æ•™è‚²èˆ‡è¼”åŠ©å·¥å…·

##### æ‡‰ç”¨å ´æ™¯
- ä½œæ¥­æ‰¹æ”¹è¼”åŠ©
- å­¸ç”Ÿç­†è¨˜æ•¸å­—åŒ–
- è€ƒè©¦ç­”æ¡ˆæƒæ
- è¦–è¦ºéšœç¤™å­¸ç”Ÿè¼”åŠ©é–±è®€

##### å¯¦æ–½æ–¹æ¡ˆ

```python
"""æ•™è‚²è¼”åŠ©å·¥å…·"""

class EducationAssistant:
    """æ•™è‚²è¼”åŠ©å·¥å…·"""
    
    def __init__(self, ocr_host="http://localhost:5000"):
        self.client = DeepSeekOCRClient(ocr_host)
    
    def read_aloud_for_visually_impaired(
        self, 
        image_path: str,
        voice_output: bool = True
    ) -> str:
        """ç‚ºè¦–è¦ºéšœç¤™è€…æœ—è®€æ–‡å­—"""
        # OCR è¾¨è­˜
        result = self.client.ocr(image_path)
        text = result['text']
        
        if voice_output:
            # ä½¿ç”¨ TTS (Text-to-Speech)
            import pyttsx3
            engine = pyttsx3.init()
            engine.say(text)
            engine.runAndWait()
        
        return text
    
    def digitize_student_notes(
        self,
        notes_dir: str,
        output_dir: str = "digitized_notes"
    ):
        """æ•¸å­—åŒ–å­¸ç”Ÿç­†è¨˜"""
        from pathlib import Path
        import datetime
        
        notes_path = Path(notes_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # æŒ‰æ—¥æœŸçµ„ç¹”ç­†è¨˜
        image_files = sorted(
            list(notes_path.glob("*.png")) + 
            list(notes_path.glob("*.jpg"))
        )
        
        all_notes = []
        
        for image_file in image_files:
            print(f"è™•ç†ç­†è¨˜: {image_file.name}")
            
            result = self.client.ocr(str(image_file))
            
            # æ·»åŠ å…ƒæ•¸æ“š
            note = {
                'date': datetime.datetime.now().strftime('%Y-%m-%d'),
                'filename': image_file.name,
                'content': result['text']
            }
            all_notes.append(note)
        
        # ç”Ÿæˆ Markdown æ ¼å¼çš„ç­†è¨˜æœ¬
        notebook_file = output_path / "notebook.md"
        with open(notebook_file, 'w', encoding='utf-8') as f:
            f.write("# æ•¸å­—åŒ–ç­†è¨˜\n\n")
            
            for note in all_notes:
                f.write(f"## {note['date']} - {note['filename']}\n\n")
                f.write(note['content'])
                f.write("\n\n---\n\n")
        
        print(f"\nå®Œæˆï¼ç­†è¨˜å·²å„²å­˜è‡³: {notebook_file}")
        return all_notes

# ä½¿ç”¨ç¯„ä¾‹
assistant = EducationAssistant()

# è¼”åŠ©é–±è®€
text = assistant.read_aloud_for_visually_impaired("textbook_page.png")

# ç­†è¨˜æ•¸å­—åŒ–
notes = assistant.digitize_student_notes("student_notes")
```

#### 4.4.5 å…¶ä»–æ‡‰ç”¨é ˜åŸŸ

##### 1. é†«ç™‚å¥åº·
- **æ‡‰ç”¨**: ç—…æ­·æ•¸å­—åŒ–ã€è™•æ–¹ç°½è­˜åˆ¥ã€é†«ç™‚å ±å‘Šæ•´ç†
- **åƒ¹å€¼**: æé«˜é†«ç™‚è¨˜éŒ„æ•ˆç‡ï¼Œæ¸›å°‘éŒ¯èª¤

##### 2. æ³•å¾‹æœå‹™
- **æ‡‰ç”¨**: åˆç´„æ–‡ä»¶æ•´ç†ã€æ³•åº­è¨˜éŒ„æ•¸å­—åŒ–ã€æ³•å¾‹æ–‡ä»¶æœå°‹
- **åƒ¹å€¼**: åŠ é€Ÿæ¡ˆä»¶è™•ç†ï¼Œæé«˜æª¢ç´¢æ•ˆç‡

##### 3. ç‰©æµé‹è¼¸
- **æ‡‰ç”¨**: å¿«éå–®æƒæã€è²¨é‹æ¨™ç±¤è­˜åˆ¥ã€å€‰å„²å–®æ“šè™•ç†
- **åƒ¹å€¼**: è‡ªå‹•åŒ–ç‰©æµæµç¨‹ï¼Œæ¸›å°‘äººå·¥è¼¸å…¥

##### 4. é›¶å”®é›»å•†
- **æ‡‰ç”¨**: å•†å“æ¨™ç±¤è­˜åˆ¥ã€åƒ¹æ ¼æ¨™ç±¤æå–ã€åº«å­˜å–®æ“šè™•ç†
- **åƒ¹å€¼**: æé«˜åº«å­˜ç®¡ç†æ•ˆç‡ï¼Œæ¸›å°‘å®šåƒ¹éŒ¯èª¤

##### 5. æ”¿åºœéƒ¨é–€
- **æ‡‰ç”¨**: å…¬æ–‡æ•¸å­—åŒ–ã€æ­·å²æª”æ¡ˆæ•´ç†ã€è­‰ä»¶è­˜åˆ¥
- **åƒ¹å€¼**: æå‡æ”¿å‹™æ•ˆç‡ï¼Œä¾¿æ°‘æœå‹™

### 4.5 é€²éšé…ç½®

#### 4.5.1 æ€§èƒ½å„ªåŒ–

##### GPU è¨˜æ†¶é«”å„ªåŒ–

```python
# ä½¿ç”¨ 4-bit é‡åŒ–é™ä½è¨˜æ†¶é«”
model = FastVisionModel.from_pretrained(
    "./deepseek_ocr",
    load_in_4bit=True,  # è¨˜æ†¶é«”é™ä½ 75%
)

# ä½¿ç”¨ 8-bit é‡åŒ–
model = FastVisionModel.from_pretrained(
    "./deepseek_ocr",
    load_in_8bit=True,  # è¨˜æ†¶é«”é™ä½ 50%
)
```

##### æ‰¹æ¬¡å¤§å°èª¿æ•´

```python
# config.py
BATCH_SIZE = 4  # æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´

# åœ¨è™•ç†æ™‚åˆ†æ‰¹
def process_large_batch(image_paths, batch_size=BATCH_SIZE):
    results = []
    for i in range(0, len(image_paths), batch_size):
        batch = image_paths[i:i+batch_size]
        batch_results = client.batch_ocr(batch)
        results.extend(batch_results)
    return results
```

#### 4.5.2 éŒ¯èª¤è™•ç†èˆ‡é‡è©¦

```python
import time
from functools import wraps

def retry_on_failure(max_retries=3, delay=1):
    """é‡è©¦è£é£¾å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    print(f"éŒ¯èª¤: {e}, é‡è©¦ {attempt + 1}/{max_retries}")
                    time.sleep(delay)
        return wrapper
    return decorator

class RobustOCRClient(DeepSeekOCRClient):
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„ OCR å®¢æˆ¶ç«¯"""
    
    @retry_on_failure(max_retries=3, delay=2)
    def ocr(self, image_path, prompt=None):
        """å¸¶é‡è©¦çš„ OCR"""
        return super().ocr(image_path, prompt)
```

---

## 5. é€²éšä¸»é¡Œ

### 5.1 æ¨¡å‹å¾®èª¿

DeepSeek-OCR æ”¯æ´é‡å°ç‰¹å®šé ˜åŸŸé€²è¡Œå¾®èª¿ï¼š

```python
from unsloth import FastVisionModel
from datasets import load_dataset

# è¼‰å…¥æ¨¡å‹
model, tokenizer = FastVisionModel.from_pretrained(
    "./deepseek_ocr",
    load_in_4bit=True,
)

# æº–å‚™ LoRA å¾®èª¿
model = FastVisionModel.get_peft_model(
    model,
    r=16,
    lora_alpha=16,
    target_modules=[
        "q_proj", "k_proj", "v_proj", "o_proj"
    ],
)

# è¼‰å…¥è¨“ç·´æ•¸æ“š
dataset = load_dataset("your_ocr_dataset")

# è¨“ç·´ï¼ˆç°¡åŒ–ç¤ºä¾‹ï¼‰
from transformers import Trainer

trainer = Trainer(
    model=model,
    train_dataset=dataset['train'],
    # ... å…¶ä»–è¨“ç·´åƒæ•¸
)

trainer.train()
```

### 5.2 å¤š GPU éƒ¨ç½²

```python
# ä½¿ç”¨ Ray Serve é€²è¡Œå¤š GPU éƒ¨ç½²
from ray import serve
import ray

ray.init()
serve.start()

@serve.deployment(num_replicas=2, ray_actor_options={"num_gpus": 1})
class DeepSeekOCRService:
    def __init__(self):
        self.model, self.tokenizer = FastVisionModel.from_pretrained(
            "./deepseek_ocr"
        )
    
    def ocr(self, image_bytes):
        # OCR è™•ç†é‚è¼¯
        pass

serve.run(DeepSeekOCRService.bind())
```

### 5.3 ç›£æ§èˆ‡æ—¥èªŒ

```python
import logging
from prometheus_client import Counter, Histogram

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ocr_service.log'),
        logging.StreamHandler()
    ]
)

# Prometheus æŒ‡æ¨™
ocr_requests = Counter('ocr_requests_total', 'Total OCR requests')
ocr_duration = Histogram('ocr_duration_seconds', 'OCR processing duration')

@ocr_duration.time()
def perform_ocr(image_path):
    ocr_requests.inc()
    # OCR è™•ç†
    pass
```

---

## 6. å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•è™•ç†å¤§å‹æ–‡æª”ï¼Ÿ

**A**: å°‡æ–‡æª”åˆ†é æƒæï¼Œä½¿ç”¨æ‰¹æ¬¡ API è™•ç†ï¼Œç„¶å¾Œåˆä½µçµæœã€‚

```python
# åˆ†é è™•ç†å¤§å‹æ–‡æª”
def process_large_document(pages_dir):
    pages = sorted(Path(pages_dir).glob("page_*.png"))
    results = client.batch_ocr([str(p) for p in pages])
    
    # åˆä½µæ‰€æœ‰é é¢
    full_text = "\n\n".join([r['text'] for r in results])
    return full_text
```

### Q2: å¦‚ä½•æé«˜è­˜åˆ¥æº–ç¢ºåº¦ï¼Ÿ

**A**: 
1. æä¾›é«˜è³ªé‡çš„åœ–ç‰‡ï¼ˆæ¸…æ™°ã€å°æ¯”åº¦é«˜ï¼‰
2. ä½¿ç”¨é©ç•¶çš„æç¤ºè©
3. é‡å°ç‰¹å®šé ˜åŸŸé€²è¡Œå¾®èª¿

### Q3: æ”¯æ´å“ªäº›åœ–ç‰‡æ ¼å¼ï¼Ÿ

**A**: PNG, JPG, JPEG, GIF, BMP, WEBP

### Q4: å¦‚ä½•è™•ç†æ‰‹å¯«æ–‡å­—ï¼Ÿ

**A**: DeepSeek-OCR åŸç”Ÿæ”¯æ´æ‰‹å¯«æ–‡å­—ï¼Œå¯ä»¥ä½¿ç”¨ç‰¹å®šæç¤ºè©ï¼š

```python
prompt = "<image>\nè«‹è­˜åˆ¥é€™å¼µåœ–ç‰‡ä¸­çš„æ‰‹å¯«æ–‡å­—ã€‚"
result = client.ocr("handwriting.png", prompt)
```

### Q5: å¯ä»¥é›¢ç·šä½¿ç”¨å—ï¼Ÿ

**A**: å¯ä»¥ï¼æ¨¡å‹ä¸‹è¼‰å¾Œå³å¯å®Œå…¨é›¢ç·šé‹è¡Œã€‚

### Q6: è¨˜æ†¶é«”éœ€æ±‚å¦‚ä½•å„ªåŒ–ï¼Ÿ

**A**: ä½¿ç”¨ 4-bit é‡åŒ–å¯é™ä½ 75% è¨˜æ†¶é«”ä½¿ç”¨ï¼š

```python
model = FastVisionModel.from_pretrained(
    "./deepseek_ocr",
    load_in_4bit=True
)
```

---

## 7. çµè«–

DeepSeek-OCR çµåˆ Unsloth å„ªåŒ–æ¡†æ¶ï¼Œæä¾›äº†æ¥­ç•Œé ˜å…ˆçš„ OCR è§£æ±ºæ–¹æ¡ˆã€‚é€šéæœ¬æ–‡æª”ï¼Œæ‚¨æ‡‰è©²èƒ½å¤ ï¼š

1. âœ… ç†è§£ DeepSeek-OCR çš„æŠ€è¡“åŸç†å’Œå„ªå‹¢
2. âœ… æŒæ¡ Unsloth çš„å„ªåŒ–æ©Ÿåˆ¶
3. âœ… å®Œæˆç³»çµ±çš„å®‰è£å’Œé…ç½®
4. âœ… ä½¿ç”¨ API é€²è¡Œå„ç¨®æ‡‰ç”¨é–‹ç™¼
5. âœ… å°‡ OCR æŠ€è¡“æ‡‰ç”¨åˆ°å¯¦éš›æ¥­å‹™å ´æ™¯

å¸Œæœ›æœ¬æ–‡æª”èƒ½å¹«åŠ©æ‚¨å……åˆ†ç™¼æ® DeepSeek-OCR çš„æ½›åŠ›ï¼

---

## 8. åƒè€ƒè³‡æº

### å®˜æ–¹æ–‡æª”
- [DeepSeek-OCR å®˜æ–¹æ–‡æª”](https://docs.unsloth.ai/new/deepseek-ocr-how-to-run-and-fine-tune)
- [Unsloth å®˜æ–¹ç¶²ç«™](https://unsloth.ai/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

### ç¤¾ç¾¤è³‡æº
- [Unsloth GitHub](https://github.com/unslothai/unsloth)
- [DeepSeek AI](https://www.deepseek.com/)

### ç›¸é—œè«–æ–‡
- DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model
- Context Optical Compression for Vision-Language Models

---

**æ–‡æª”ç‰ˆæœ¬**: 1.0.0  
**æœ€å¾Œæ›´æ–°**: 2025-11-10  
**ç¶­è­·è€…**: DeepSeek-OCR API Team  
**æˆæ¬Š**: MIT License

